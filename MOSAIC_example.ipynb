{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "import itertools\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import floor\n",
    "from functools import reduce\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    brier_score_loss,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    precision_recall_curve\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import linalg as LA\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, SequentialSampler\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set up device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.best_model = None\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_model = model\n",
    "            self.val_loss_min = val_loss\n",
    "        elif score < self.best_score - self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.val_loss_min = val_loss\n",
    "            self.best_model = model\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCGrad():\n",
    "    def __init__(self, optimizer, reduction='mean'):\n",
    "        self._optim, self._reduction = optimizer, reduction\n",
    "        return\n",
    "\n",
    "    @property\n",
    "    def optimizer(self):\n",
    "        return self._optim\n",
    "\n",
    "    def zero_grad(self):\n",
    "        return self._optim.zero_grad(set_to_none=True)\n",
    "\n",
    "    def step(self):\n",
    "        return self._optim.step()\n",
    "\n",
    "    def pc_backward(self, objectives):\n",
    "        grads, shapes, has_grads = self._pack_grad(objectives)\n",
    "        pc_grad = self._project_conflicting(grads, has_grads)\n",
    "        pc_grad = self._unflatten_grad(pc_grad, shapes[0])\n",
    "        self._set_grad(pc_grad)\n",
    "        return\n",
    "\n",
    "    def _project_conflicting(self, grads, has_grads, shapes=None):\n",
    "        shared = torch.stack(has_grads).prod(0).bool()\n",
    "        pc_grad, num_task = copy.deepcopy(grads), len(grads)\n",
    "        for g_i in pc_grad:\n",
    "            random.shuffle(grads)\n",
    "            for g_j in grads:\n",
    "                g_i_g_j = torch.dot(g_i, g_j)\n",
    "                if g_i_g_j < 0:\n",
    "                    g_i -= (g_i_g_j) * g_j / (g_j.norm() ** 2)\n",
    "        merged_grad = torch.zeros_like(grads[0]).to(grads[0].device)\n",
    "        if self._reduction:\n",
    "            merged_grad[shared] = torch.stack([g[shared]\n",
    "                                               for g in pc_grad]).mean(dim=0)\n",
    "        elif self._reduction == 'sum':\n",
    "            merged_grad[shared] = torch.stack([g[shared]\n",
    "                                               for g in pc_grad]).sum(dim=0)\n",
    "        else:\n",
    "            exit('invalid reduction method')\n",
    "\n",
    "        merged_grad[~shared] = torch.stack([g[~shared]\n",
    "                                            for g in pc_grad]).sum(dim=0)\n",
    "        return merged_grad\n",
    "\n",
    "    def _set_grad(self, grads):\n",
    "        idx = 0\n",
    "        for group in self._optim.param_groups:\n",
    "            for p in group['params']:\n",
    "                p.grad = grads[idx]\n",
    "                idx += 1\n",
    "        return\n",
    "\n",
    "    def _pack_grad(self, objectives):\n",
    "        grads, shapes, has_grads = [], [], []\n",
    "        for obj in objectives:\n",
    "            self._optim.zero_grad(set_to_none=True)\n",
    "            obj.backward(retain_graph=True)\n",
    "            grad, shape, has_grad = self._retrieve_grad()\n",
    "            grads.append(self._flatten_grad(grad, shape))\n",
    "            has_grads.append(self._flatten_grad(has_grad, shape))\n",
    "            shapes.append(shape)\n",
    "        return grads, shapes, has_grads\n",
    "\n",
    "    def _unflatten_grad(self, grads, shapes):\n",
    "        unflatten_grad, idx = [], 0\n",
    "        for shape in shapes:\n",
    "            length = np.prod(shape)\n",
    "            unflatten_grad.append(grads[idx:idx + length].view(shape).clone())\n",
    "            idx += length\n",
    "        return unflatten_grad\n",
    "\n",
    "    def _flatten_grad(self, grads, shapes):\n",
    "        flatten_grad = torch.cat([g.flatten() for g in grads])\n",
    "        return flatten_grad\n",
    "\n",
    "    def _retrieve_grad(self):\n",
    "        grad, shape, has_grad = [], [], []\n",
    "        for group in self._optim.param_groups:\n",
    "            for p in group['params']:\n",
    "                # if p.grad is None: continue\n",
    "                # tackle the multi-head scenario\n",
    "                if p.grad is None:\n",
    "                    shape.append(p.shape)\n",
    "                    grad.append(torch.zeros_like(p).to(p.device))\n",
    "                    has_grad.append(torch.zeros_like(p).to(p.device))\n",
    "                    continue\n",
    "                shape.append(p.grad.shape)\n",
    "                grad.append(p.grad.clone())\n",
    "                has_grad.append(torch.ones_like(p).to(p.device))\n",
    "        return grad, shape, has_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)  \n",
    "    torch.cuda.manual_seed(seed)  \n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "    torch.backends.cudnn.deterministic = True  \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)  \n",
    "    random.seed(seed) \n",
    "seed_everything(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_1(nn.Module):\n",
    "    def __init__(self, dim, int_dim, shell):\n",
    "        super(CNN_1, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=shell, stride=shell, padding=0),\n",
    "            nn.BatchNorm1d(16)\n",
    "        )\n",
    "        self.fc = nn.Linear(dim, int_dim)\n",
    "        self.fc2 = nn.Linear(int_dim, 1)\n",
    "\n",
    "        self.act = nn.Tanh()\n",
    "        self.pool = nn.MaxPool1d(2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.view(x.shape[0], 1, -1)\n",
    "        out = self.conv(x)\n",
    "        out = self.act(out)\n",
    "        out = self.pool(out)\n",
    "        out = out.view(x.shape[0], out.size(1) * out.size(2))\n",
    "        feat = self.fc(out)\n",
    "        logit = self.fc2(feat)\n",
    "        logit = logit.view(-1, )\n",
    "\n",
    "        return logit, feat\n",
    "\n",
    "\n",
    "class CNN_2(nn.Module):\n",
    "    def __init__(self, dim, int_dim, shell):\n",
    "        super(CNN_2, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=shell, stride=shell, padding=0),\n",
    "            nn.BatchNorm1d(16)\n",
    "        )\n",
    "        self.fc = nn.Linear(dim, int_dim)\n",
    "        self.fc2 = nn.Linear(int_dim, 1)\n",
    "\n",
    "        self.act = nn.Tanh()\n",
    "        self.pool = nn.MaxPool1d(2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], 1, -1)\n",
    "        out = self.conv(x)\n",
    "        out = self.act(out)\n",
    "        out = self.pool(out)\n",
    "        out = out.view(x.shape[0], out.size(1) * out.size(2))\n",
    "        feat = self.fc(out)\n",
    "        logit = self.fc2(feat)\n",
    "        logit = logit.view(-1, )\n",
    "\n",
    "        return logit, feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_x, valid_x, tr_y, val_y, model, patience, n_epochs, optimizer, rg):\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    avg_train_losses = []\n",
    "    avg_valid_losses = []\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output, feat = model(train_x)\n",
    "        # calculate the loss\n",
    "        alpha_t = 0.8 * ((early_stopping.counter + 1) / patience)\n",
    "        alpha_t = max(0, alpha_t)\n",
    "        if epoch == 1:\n",
    "            before_predict = tr_y.float()\n",
    "\n",
    "        loss1 = loss_func(output, tr_y.float())\n",
    "        target = Variable(torch.where(tr_y.float() > 0, 1, -1))\n",
    "        loss2 = loss_func2(torch.sigmoid(output), before_predict, target)\n",
    "        loss = ((1 - alpha_t) * loss1 + (alpha_t) * loss2)\n",
    "\n",
    "        norm = torch.cuda.FloatTensor([0])\n",
    "        for parameter in model.parameters():\n",
    "            norm += torch.norm(parameter, p=1)\n",
    "\n",
    "        loss = loss + norm * rg\n",
    "\n",
    "        before_predict = torch.sigmoid(output).detach()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        ######################\n",
    "        # validate the model #\n",
    "        ######################\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            output, feat = model(valid_x)\n",
    "            loss = loss_func(output, val_y.float())\n",
    "\n",
    "            # record validation loss\n",
    "            valid_losses.append(loss.item())\n",
    "\n",
    "        # calculate average loss over an epoch\n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "\n",
    "        epoch_len = len(str(n_epochs))\n",
    "\n",
    "        print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {train_loss:.5f} ' +\n",
    "                     f'valid_loss: {valid_loss:.5f}')\n",
    "        #print(print_msg)\n",
    "\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        early_stopping(valid_loss, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "\n",
    "    return early_stopping.best_model, early_stopping.val_loss_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, num_feature, num_node, bias=False):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(num_node, num_node, kernel_size=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(num_feature, num_feature, kernel_size=1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv1(x)\n",
    "        h = h - x\n",
    "        h = self.relu(self.conv2(h.permute(0, 2, 1)).permute(0, 2, 1))\n",
    "        return h\n",
    "\n",
    "class BilateralGCN(nn.Module):\n",
    "    def __init__(self, in_feature, num_node):\n",
    "        super().__init__()\n",
    "        self.gcn = GCN(in_feature, num_node)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        fusion = x + y\n",
    "        fusion = self.gcn(fusion)\n",
    "        x = x + fusion\n",
    "        y = y + fusion\n",
    "\n",
    "        return x, y\n",
    "\n",
    "class clffusion(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super(clffusion, self).__init__()\n",
    "        self.num_n = in_dim // 4\n",
    "        self.num_s = in_dim // 2\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_dim, self.num_n, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_dim, self.num_s, kernel_size=1)\n",
    "\n",
    "        self.BGCN = BilateralGCN(self.num_s, self.num_n)\n",
    "\n",
    "        self.conv = nn.Conv1d(self.num_s, in_dim, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm1d(in_dim)\n",
    "        self.in_dim = in_dim\n",
    "\n",
    "        self.clf1 = nn.Linear(in_dim, 1)\n",
    "        self.clf2 = nn.Linear(in_dim, 1)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        n = x1.size(0)\n",
    "        e = torch.bmm(x1.reshape(n, 1, -1).permute(0, 2, 1), x2.reshape(n, 1, -1))\n",
    "        s1 = self.softmax(e.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        s2 = self.softmax(e).permute(0, 2, 1)\n",
    "\n",
    "        x1 = torch.bmm(x1.reshape(n, 1, -1), s1)\n",
    "        x2 = torch.bmm(x2.reshape(n, 1, -1), s2)\n",
    "\n",
    "        x1 = x1.permute(0, 2, 1)\n",
    "        x2 = x2.permute(0, 2, 1)\n",
    "\n",
    "        x1_v = self.conv1(x1)\n",
    "        x2_v = self.conv1(x2)\n",
    "        x1_w = self.conv2(x1)\n",
    "        x2_w = self.conv2(x2)\n",
    "\n",
    "        x1_g = torch.bmm(x1_v, torch.transpose(x1_w, 1, 2))\n",
    "        x2_g = torch.bmm(x2_v, torch.transpose(x2_w, 1, 2))\n",
    "\n",
    "        x1_g, x2_g = self.BGCN(x1_g, x2_g)\n",
    "        x1_g = torch.bmm(torch.transpose(x1_v, 1, 2), x1_g).view(n, self.num_s, -1)\n",
    "        x2_g = torch.bmm(torch.transpose(x2_v, 1, 2), x2_g).view(n, self.num_s, -1)\n",
    "\n",
    "        x1_fusion = self.conv(x1_g)\n",
    "        x2_fusion = self.conv(x2_g)\n",
    "\n",
    "        x1_fusion = F.relu(self.bn(x1_fusion))\n",
    "        x2_fusion = F.relu(self.bn(x2_fusion))\n",
    "\n",
    "        res1 = (x1 + x1_fusion).view(n, self.in_dim)\n",
    "        res2 = (x2 + x2_fusion).view(n, self.in_dim)\n",
    "\n",
    "        logit1 = self.clf1(res1).view(-1)\n",
    "        logit2 = self.clf2(res2).view(-1)\n",
    "\n",
    "        return logit1, logit2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fusion_model(tr1, tr2, val1, val2, clf, patience, n_epochs, tr_y_clf, val_y, hard_ind, opt):\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    clf.train()\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        if early_stopping.counter < (patience//2):\n",
    "            tr_x1 = tr1[~hard_ind]\n",
    "            tr_x2 = tr2[~hard_ind]\n",
    "            tr_y = tr_y_clf[~hard_ind]\n",
    "        else:\n",
    "            tr_x1 = tr1\n",
    "            tr_x2 = tr2\n",
    "            tr_y = tr_y_clf\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        opt.zero_grad()\n",
    "        output1, output2 = clf(tr_x1, tr_x2)\n",
    "\n",
    "        loss1 = loss_func(output1, tr_y.float())\n",
    "        loss2 = loss_func(output2, tr_y.float())\n",
    "        loss = loss1 + loss2\n",
    "        losses = [loss1, loss2]\n",
    "\n",
    "        opt.zero_grad()\n",
    "        opt.pc_backward(losses)\n",
    "        opt.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        ######################\n",
    "        # validate the model #\n",
    "        ######################\n",
    "        with torch.no_grad():\n",
    "            clf.eval()\n",
    "            output1, output2 = clf(val1, val2)\n",
    "\n",
    "            loss1 = loss_func(output1, val_y.float())\n",
    "            loss2 = loss_func(output2, val_y.float())\n",
    "            loss = loss1 + loss2\n",
    "\n",
    "            valid_losses.append(loss.item())\n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "\n",
    "        early_stopping(valid_loss, clf)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            break\n",
    "    best_clf = early_stopping.best_model\n",
    "\n",
    "    return best_clf, early_stopping.val_loss_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        # torch.nn.init.zeros_(m.bias)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        # torch.nn.init.zeros_(m.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17996, 3078)\n",
      "(743, 3078)\n"
     ]
    }
   ],
   "source": [
    "rg = 0.001\n",
    "learning_rate = 0.0001\n",
    "lr1 = 0.0001\n",
    "lr2 = 0.0001\n",
    "n_epochs = 3000\n",
    "patience = 30\n",
    "\n",
    "type = './data/'\n",
    "x1 = pd.read_csv(type + 'mRNA.csv', index_col=0, delimiter=',')\n",
    "x2 = pd.read_csv(type + 'miRNA.csv', index_col=0, delimiter=',')\n",
    "label = pd.read_csv(type + 'label.csv',  index_col=0,delimiter=',')\n",
    "\n",
    "print(x1.shape)\n",
    "print(x2.shape)\n",
    "x1 = x1.fillna(0)\n",
    "x2 = x2.fillna(0)\n",
    "labels = np.array(label).flatten().astype(np.float32)\n",
    "\n",
    "shell_list = list(range(10, 300, 30))\n",
    "int_dim_list = [300, 100, 50]\n",
    "rg_list = [0.0, 0.001,0.0001]\n",
    "\n",
    "loss_func = nn.BCEWithLogitsLoss(weight=None, size_average=None, reduce=None, reduction='mean')\n",
    "loss_func2 = nn.MarginRankingLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Fold : 1-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [31:14<00:00, 624.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8548710242925119\n",
      "Task2 test AUC: 0.852335336839469\n",
      "------------- Fold : 2-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [27:12<00:00, 544.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8195592286501376\n",
      "Task2 test AUC: 0.8280428249436513\n",
      "------------- Fold : 3-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [29:15<00:00, 585.01s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8728243175557225\n",
      "Task2 test AUC: 0.8708208114199849\n",
      "------------- Fold : 4-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [33:51<00:00, 677.19s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8208427247683444\n",
      "Task2 test AUC: 0.827541948409717\n",
      "------------- Fold : 5-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [29:12<00:00, 584.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.857031054345104\n",
      "Task2 test AUC: 0.858564988730278\n",
      "Task1: AUC 0.845025669922364\n",
      "Task2: AUC 0.84746118206862\n",
      "------------- Fold : 1-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [30:58<00:00, 619.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8227366641622841\n",
      "Task2 test AUC: 0.8277923866766842\n",
      "------------- Fold : 2-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [31:25<00:00, 628.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8708051590282996\n",
      "Task2 test AUC: 0.8720730027548209\n",
      "------------- Fold : 3-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [29:43<00:00, 594.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8323628850488356\n",
      "Task2 test AUC: 0.8393281993488605\n",
      "------------- Fold : 4-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [32:56<00:00, 658.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8482031054345104\n",
      "Task2 test AUC: 0.844743926872026\n",
      "------------- Fold : 5-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [29:08<00:00, 582.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8640276734284998\n",
      "Task2 test AUC: 0.8596293513648885\n",
      "Task1: AUC 0.8476270974204858\n",
      "Task2: AUC 0.8487133734034561\n",
      "------------- Fold : 1-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [29:31<00:00, 590.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.84070560981718\n",
      "Task2 test AUC: 0.8343976959679439\n",
      "------------- Fold : 2-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [28:37<00:00, 572.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8413786626596544\n",
      "Task2 test AUC: 0.8390621086902078\n",
      "------------- Fold : 3-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [31:56<00:00, 638.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8648415977961431\n",
      "Task2 test AUC: 0.8659998747808666\n",
      "------------- Fold : 4-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [29:33<00:00, 591.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8264306286000501\n",
      "Task2 test AUC: 0.8174461557726019\n",
      "------------- Fold : 5-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [31:27<00:00, 629.07s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8472326571500126\n",
      "Task2 test AUC: 0.851740545955422\n",
      "Task1: AUC 0.844117831204608\n",
      "Task2: AUC 0.8417292762334083\n",
      "------------- Fold : 1-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [31:33<00:00, 631.23s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8594102178812922\n",
      "Task2 test AUC: 0.8617111194590533\n",
      "------------- Fold : 2-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [29:54<00:00, 598.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8344446531430002\n",
      "Task2 test AUC: 0.8305315552216379\n",
      "------------- Fold : 3-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [31:21<00:00, 627.11s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8482813673929378\n",
      "Task2 test AUC: 0.8470291760581016\n",
      "------------- Fold : 4-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [32:29<00:00, 649.72s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8316428750313049\n",
      "Task2 test AUC: 0.8382168795391937\n",
      "------------- Fold : 5-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [32:44<00:00, 654.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8409560480841471\n",
      "Task2 test AUC: 0.8413160530929126\n",
      "Task1: AUC 0.8429470323065363\n",
      "Task2: AUC 0.8437609566741797\n",
      "------------- Fold : 1-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [30:41<00:00, 613.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8595197846230903\n",
      "Task2 test AUC: 0.8621963436013023\n",
      "------------- Fold : 2-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [28:14<00:00, 564.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8470761332331579\n",
      "Task2 test AUC: 0.8492987728524918\n",
      "------------- Fold : 3-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [26:59<00:00, 539.79s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8656398697721012\n",
      "Task2 test AUC: 0.8697564487853745\n",
      "------------- Fold : 4-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [28:28<00:00, 569.62s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.7913066616579013\n",
      "Task2 test AUC: 0.7849987478086653\n",
      "------------- Fold : 5-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [31:47<00:00, 635.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8447282744803406\n",
      "Task2 test AUC: 0.8468413473578762\n",
      "Task1: AUC 0.8416541447533182\n",
      "Task2: AUC 0.842618332081142\n",
      "------------- Fold : 1-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [20:53<00:00, 417.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8449474079639369\n",
      "Task2 test AUC: 0.8507700976709242\n",
      "------------- Fold : 2-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [26:40<00:00, 533.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8551684197345354\n",
      "Task2 test AUC: 0.8607250187828699\n",
      "------------- Fold : 3-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [26:39<00:00, 533.16s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8500031304783371\n",
      "Task2 test AUC: 0.8500344352617081\n",
      "------------- Fold : 4-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [34:35<00:00, 691.87s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8170861507638366\n",
      "Task2 test AUC: 0.8216566491359879\n",
      "------------- Fold : 5-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [33:18<00:00, 666.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8595510894064613\n",
      "Task2 test AUC: 0.8590502128725269\n",
      "Task1: AUC 0.8453512396694215\n",
      "Task2: AUC 0.8484472827448034\n",
      "------------- Fold : 1-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [29:10<00:00, 583.66s/it]\n",
      "100%|██████████| 3/3 [28:46<00:00, 575.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8657024793388431\n",
      "Task2 test AUC: 0.865358126721763\n",
      "------------- Fold : 3-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [30:42<00:00, 614.05s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8589876033057852\n",
      "Task2 test AUC: 0.8629476584022038\n",
      "------------- Fold : 4-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [29:20<00:00, 586.82s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8059259954921112\n",
      "Task2 test AUC: 0.8112634610568495\n",
      "------------- Fold : 5-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [33:52<00:00, 677.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8589876033057852\n",
      "Task2 test AUC: 0.8579388930628602\n",
      "Task1: AUC 0.8459898572501879\n",
      "Task2: AUC 0.8456862008514902\n",
      "------------- Fold : 1-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [33:00<00:00, 660.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8761739293764087\n",
      "Task2 test AUC: 0.8808539944903581\n",
      "------------- Fold : 2-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [27:42<00:00, 554.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8613354620586026\n",
      "Task2 test AUC: 0.8633233158026545\n",
      "------------- Fold : 3-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [26:12<00:00, 524.03s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8608658903080391\n",
      "Task2 test AUC: 0.8590815176558979\n",
      "------------- Fold : 4-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [28:11<00:00, 563.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8172113698973202\n",
      "Task2 test AUC: 0.8147695967943902\n",
      "------------- Fold : 5-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [28:03<00:00, 561.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8289506636614075\n",
      "Task2 test AUC: 0.832206361131981\n",
      "Task1: AUC 0.8489074630603556\n",
      "Task2: AUC 0.8500469571750564\n",
      "------------- Fold : 1-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [29:42<00:00, 594.27s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8533057851239669\n",
      "Task2 test AUC: 0.8503161783120462\n",
      "------------- Fold : 2-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [28:41<00:00, 573.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8291228399699475\n",
      "Task2 test AUC: 0.8257419233658903\n",
      "------------- Fold : 3-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [29:40<00:00, 593.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8496118206862009\n",
      "Task2 test AUC: 0.8520692461808165\n",
      "------------- Fold : 4-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [30:54<00:00, 618.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8633076634109692\n",
      "Task2 test AUC: 0.8569527923866765\n",
      "------------- Fold : 5-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [18:54<00:00, 378.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8293106686701728\n",
      "Task2 test AUC: 0.8321750563486101\n",
      "Task1: AUC 0.8449317555722514\n",
      "Task2: AUC 0.8434510393188079\n",
      "------------- Fold : 1-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [28:51<00:00, 577.06s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8700694966190834\n",
      "Task2 test AUC: 0.865389431505134\n",
      "------------- Fold : 2-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [30:05<00:00, 601.96s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8184948660155273\n",
      "Task2 test AUC: 0.8236601552717255\n",
      "------------- Fold : 3-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [26:18<00:00, 526.16s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8919515401953418\n",
      "Task2 test AUC: 0.8901984723265715\n",
      "------------- Fold : 4-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [24:24<00:00, 488.30s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8312359128474831\n",
      "Task2 test AUC: 0.8330046331079389\n",
      "------------- Fold : 5-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [31:10<00:00, 623.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task1 test AUC: 0.8347577009767093\n",
      "Task2 test AUC: 0.8343820435762584\n",
      "Task1: AUC 0.849301903330829\n",
      "Task2: AUC 0.8493269471575257\n",
      "-----------------------------------\n",
      "Task1 Average: AUC 0.8455853994490358 0.0023354978898925335\n",
      "Task2 Average: AUC 0.8461241547708489 0.0028993565091317815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_f1 = x1.shape[0]\n",
    "n_f2 = x2.shape[0]\n",
    "\n",
    "x1 = torch.tensor(x1.values)\n",
    "x2 = torch.tensor(x2.values)\n",
    "\n",
    "t1_res = []\n",
    "t2_res = []\n",
    "\n",
    "for it in range(0, 10):\n",
    "\n",
    "    t1_auc = []\n",
    "    t2_auc = []\n",
    "\n",
    "    kf = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=it)\n",
    "    train_index = []\n",
    "    valid_index = []\n",
    "    test_index = []\n",
    "    \n",
    "    for tr_index, te_index in kf.split(np.transpose(x1), labels):\n",
    "        random.shuffle(tr_index)\n",
    "        tmp = int(0.2 * len(tr_index))\n",
    "\n",
    "        train_index.append(tr_index[tmp + 1:])\n",
    "        valid_index.append(tr_index[0:tmp])\n",
    "        test_index.append(te_index)\n",
    "\n",
    "    seed_everything(it)\n",
    "\n",
    "    for fold in range(1, 6):\n",
    "        print(\"------------- Fold : \" + str(fold) + \"-------------\")\n",
    "        y = torch.tensor(labels)\n",
    "        train_y = y[train_index[fold - 1]]\n",
    "        valid_y = y[valid_index[fold - 1]]\n",
    "        test_y = y[test_index[fold - 1]]\n",
    "\n",
    "        train_y = Variable(train_y.type(torch.LongTensor)).to(device)\n",
    "        valid_y = Variable(valid_y.type(torch.LongTensor)).to(device)\n",
    "        test_y = Variable(test_y.type(torch.LongTensor))\n",
    "\n",
    "        tr_x1 = x1[:, train_index[fold - 1]].t()\n",
    "        val_x1 = x1[:, valid_index[fold - 1]].t()\n",
    "        te_x1 = x1[:, test_index[fold - 1]].t()\n",
    "        tr_x1 = torch.reshape(tr_x1, (tr_x1.shape[0], tr_x1.shape[1], 1))\n",
    "        val_x1 = torch.reshape(val_x1, (val_x1.shape[0], val_x1.shape[1], 1))\n",
    "        te_x1 = torch.reshape(te_x1, (te_x1.shape[0], te_x1.shape[1], 1))\n",
    "\n",
    "        tr_x1 = Variable(tr_x1.type(torch.FloatTensor)).to(device)\n",
    "        val_x1 = Variable(val_x1.type(torch.FloatTensor)).to(device)\n",
    "        te_x1 = Variable(te_x1.type(torch.FloatTensor)).to(device)\n",
    "\n",
    "        tr_x2 = x2[:, train_index[fold - 1]].t()\n",
    "        val_x2 = x2[:, valid_index[fold - 1]].t()\n",
    "        te_x2 = x2[:, test_index[fold - 1]].t()\n",
    "\n",
    "        tr_x2 = torch.reshape(tr_x2, (tr_x2.shape[0], tr_x2.shape[1], 1))\n",
    "        val_x2 = torch.reshape(val_x2, (val_x2.shape[0], val_x2.shape[1], 1))\n",
    "        te_x2 = torch.reshape(te_x2, (te_x2.shape[0], te_x2.shape[1], 1))\n",
    "\n",
    "        tr_x2 = Variable(tr_x2.type(torch.FloatTensor)).to(device)\n",
    "        val_x2 = Variable(val_x2.type(torch.FloatTensor)).to(device)\n",
    "        te_x2 = Variable(te_x2.type(torch.FloatTensor)).to(device)\n",
    "\n",
    "        best_val = 9999\n",
    "        for in_dim in tqdm(range(0, len(int_dim_list))):\n",
    "            int_dim = int_dim_list[in_dim]\n",
    "\n",
    "            # Omics1\n",
    "            best_val1 = 9999\n",
    "            for s in range(0, len(shell_list)):\n",
    "                for r in range(0, len(rg_list)):\n",
    "                    rg = rg_list[r]\n",
    "                    shell = shell_list[s]\n",
    "                    dim = 16 * int(int(n_f1 / shell) / 2)\n",
    "                    model = CNN_1(dim, int_dim, shell).to(device)\n",
    "                    optimizer = torch.optim.Adam(model.parameters(), lr=lr1)\n",
    "                    m1, valid_loss = train_model(tr_x1, val_x1, train_y, valid_y, model, patience, 1000,\n",
    "                                                           optimizer, rg)\n",
    "                    if valid_loss < best_val1:\n",
    "                        best_val1 = valid_loss\n",
    "                        best_model1 = m1\n",
    "                        shell1 = shell\n",
    "            # Embedding\n",
    "            logit_x1, tr_f1 = best_model1(tr_x1)\n",
    "            _, val_f1 = best_model1(val_x1)\n",
    "            _, te_f1 = best_model1(te_x1)\n",
    "\n",
    "            # Omics2\n",
    "            best_val2 = 9999\n",
    "            for s in range(0, len(shell_list)):\n",
    "                for r in range(0, len(rg_list)):\n",
    "                    rg = rg_list[r]\n",
    "                    shell = shell_list[s]\n",
    "                    dim = 16 * int(int(n_f2 / shell) / 2)\n",
    "                    model = CNN_2(dim, int_dim, shell).to(device)\n",
    "                    optimizer = torch.optim.Adam(model.parameters(), lr=lr2)\n",
    "\n",
    "                    m2, valid_loss = train_model(tr_x2, val_x2, train_y, valid_y, model, patience, 1000,\n",
    "                                                           optimizer, rg)\n",
    "                    if valid_loss < best_val2:\n",
    "                        best_val2 = valid_loss\n",
    "                        best_model2 = m2\n",
    "                        shell2 = shell\n",
    "            # Embedding\n",
    "            logit_x2, tr_f2 = best_model2(tr_x2)\n",
    "            _, val_f2 = best_model2(val_x2)\n",
    "            _, te_f2 = best_model2(te_x2)\n",
    "\n",
    "            # Delete for memory\n",
    "            del (m1)\n",
    "            del (m2)\n",
    "            del (best_model1)\n",
    "            del (best_model2)\n",
    "            gc.collect()\n",
    "\n",
    "            res1 = abs(train_y - torch.sigmoid(logit_x1))\n",
    "            logit_mean1 = torch.mean(res1)\n",
    "            ind1 = (res1 > logit_mean1)\n",
    "            res2 = abs(train_y - torch.sigmoid(logit_x2))\n",
    "            logit_mean2 = torch.mean(res2)\n",
    "            ind2 = (res2 > logit_mean2)\n",
    "\n",
    "            # Training fusion block\n",
    "            inter_ind = (ind1 & ind2)\n",
    "            clf = clffusion(int_dim).cuda()\n",
    "            optimizer_f = PCGrad(torch.optim.SGD(clf.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005,\n",
    "                                                 nesterov=True))\n",
    "            best, f_val_loss = train_fusion_model(tr_f1.detach(), tr_f2.detach(), val_f1.detach(), val_f2.detach(),\n",
    "                                                  clf, patience, 300, train_y, valid_y, inter_ind, optimizer_f)\n",
    "            if f_val_loss < best_val:\n",
    "                best_val = f_val_loss\n",
    "                res1, res2 = best(te_f1.detach(), te_f2.detach())\n",
    "                y_pred1 = torch.sigmoid(res1).detach().cpu()\n",
    "                y_pred2 = torch.sigmoid(res2).detach().cpu()\n",
    "\n",
    "                # Task1 performance\n",
    "                fpr, tpr, threshold = metrics.roc_curve(test_y, y_pred1)\n",
    "                roc_auc1 = metrics.auc(fpr, tpr)\n",
    "\n",
    "                # Task2 performance\n",
    "                fpr, tpr, threshold = metrics.roc_curve(test_y, y_pred2)\n",
    "                roc_auc2 = metrics.auc(fpr, tpr)\n",
    "\n",
    "        t1_auc.append(roc_auc1)\n",
    "        print(\"Task1 test AUC:\", roc_auc1)\n",
    "        t2_auc.append(roc_auc2)\n",
    "        print(\"Task2 test AUC:\", roc_auc2)\n",
    "\n",
    "    t1_res.append(sum(t1_auc) / len(t1_auc))\n",
    "    t2_res.append(sum(t2_auc) / len(t2_auc))\n",
    "\n",
    "    # Average performance at each epoch\n",
    "    print(\"Task1: AUC\", sum(t1_auc) / len(t1_auc))\n",
    "    print(\"Task2: AUC\", sum(t2_auc) / len(t2_auc))\n",
    "\n",
    "# Final performance\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Task1 Average: AUC\", sum(t1_res) / len(t1_res), np.std(t1_res))\n",
    "print(\"Task2 Average: AUC\", sum(t2_res) / len(t2_res), np.std(t2_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
